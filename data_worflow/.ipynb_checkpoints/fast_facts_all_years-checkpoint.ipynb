{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Environment\n",
    "Set up environment for querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import csv\n",
    "import operator\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.22.169.173:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x111028dd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setting python path for data and setting data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/abuckfire/side-projects/arson')\n",
    "import static_data.fire_codes.lookup_tables as codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "years_available = map(str, range(2009, 2015))\n",
    "file_prefix = \"nfirs_arson_\"\n",
    "arson_data_path = os.path.join(\"..\", \"static_data\", \"nfirs_arson\")\n",
    "fire_depts_data_path = os.path.join(\"..\", \"static_data\", \"nfirs_fire_depts\")\n",
    "pop_by_zipcode_csv = os.path.join(\"..\", \"static_data\", \"zipcodes\", \"pop_per_zip.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Initializing Spark Context and reading data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "depts = spark.read.csv(fire_depts_data_path + \"/nfirs_arson_\" + \"2009.csv\", header=True).select([\"state\", \"fdid\"])\n",
    "arson_df = spark.read.csv(arson_data_path + \"/nfirs_arson_\" + \"2009.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_on_zip = arson.join(depts, ['state','fdid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = \"count\"\n",
    "STATE = \"state\"\n",
    "UNKNOWNS = [\"UU\", \"NN\", None]\n",
    "\n",
    "YEARS_AVAILABLE = map(str, range(2009, 2015))\n",
    "FILE_PREFIX = \"nfirs_arson_\"\n",
    "ARSON_PATH = os.path.join(\"..\", \"static_data\", \"nfirs_arson\")\n",
    "DEPTS_PATH = os.path.join(\"..\", \"static_data\", \"nfirs_fire_depts\")\n",
    "ZIPCODES_PATH = os.path.join(\"..\", \"static_data\", \"zipcodes\", \"pop_per_zip.csv\")\n",
    "\n",
    "\n",
    "def lookup_code(candidate_list, column, codebook):\n",
    "    candidates = [row for row in candidate_list if row[column] not in UNKNOWNS]\n",
    "    if candidates:\n",
    "        return codebook[max(candidates, key=operator.itemgetter(1))[0]]\n",
    "    return None\n",
    "\n",
    "def build_max_count_dicts(df, column, codebook, state_codes=STATES):\n",
    "    results = collections.defaultdict()\n",
    "    for state in state_codes:\n",
    "        count_list = df[df.state==state].select(column, COUNT).collect()\n",
    "        results[state] = lookup_code(count_list, column, codebook)\n",
    "\n",
    "    overall_res_df = df.groupBy(column).agg(functions.sum(COUNT))\n",
    "    results[\"overall\"] = lookup_code(overall_res_df, column, codebook)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_motives(df, column=\"motivation\"):\n",
    "    df1 = df.groupBy([\"mot_facts1\", STATE]).count().withColumnRenamed(\"mot_facts1\", column).withColumnRenamed(COUNT, \"count_1\")\n",
    "    df2 = df.groupBy([\"mot_facts2\", STATE]).count().withColumnRenamed(\"mot_facts2\", column).withColumnRenamed(COUNT, \"count_2\")\n",
    "    df3 = df.groupBy([\"mot_facts3\", STATE]).count().withColumnRenamed(\"mot_facts3\", column).withColumnRenamed(COUNT, \"count_3\")\n",
    "\n",
    "    motives = df1.join(df2, [column, STATE], \"outer\").join(df3, [column, STATE], \"outer\").na.fill(0)\n",
    "\n",
    "    motives_per_state = motives.withColumn(COUNT, sum(motives[col] for col in [\"count_1\", \"count_2\", \"count_3\"]))\n",
    "    motives_per_state.show()\n",
    "    return motives_per_state\n",
    "    #return build_max_count_dicts(motives_per_state, column, codes.SUSPECTED_MOTIVATION_FACTORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "arson_df = spark.read.csv(arson_data_path + \"/nfirs_arson_\" + \"2009.csv\", header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------+-------+-------+-----+\n",
      "|motivation|state|count_1|count_2|count_3|count|\n",
      "+----------+-----+-------+-------+-------+-----+\n",
      "|        13|   NJ|      1|      0|      0|    1|\n",
      "|        43|   MT|      1|      0|      0|    1|\n",
      "|        00|   MO|      1|      0|      0|    1|\n",
      "|        14|   NJ|      3|      1|      0|    4|\n",
      "|        21|   IN|      8|      3|      0|   11|\n",
      "|        23|   NY|      1|      0|      0|    1|\n",
      "|        13|   CA|      7|      2|      0|    9|\n",
      "|        13|   DC|      2|      0|      0|    2|\n",
      "|        63|   HI|      2|      0|      0|    2|\n",
      "|        00|   NE|      7|      2|      0|    9|\n",
      "|        12|   VA|      0|      1|      0|    1|\n",
      "|        22|   MN|      1|      0|      0|    1|\n",
      "|        44|   TX|      2|      1|      0|    3|\n",
      "|        54|   PA|      2|      0|      0|    2|\n",
      "|      null|   AZ|    508|      0|      0|  508|\n",
      "|      null|   AZ|      0|    556|      0|  556|\n",
      "|      null|   SC|    344|      0|      0|  344|\n",
      "|      null|   SC|      0|    400|      0|  400|\n",
      "|      null|   AZ|      0|      0|    561|  561|\n",
      "|      null|   SC|      0|      0|    408|  408|\n",
      "+----------+-----+-------+-------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "motives_per_state = get_motives(arson_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: What is the most common motivation for starting a fire?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = arson_df.groupBy([\"mot_facts1\", \"state\"]).count().withColumnRenamed(\"mot_facts1\", \"motivation\").withColumnRenamed(\"count\", \"count_1\")\n",
    "df2 = arson_df.groupBy([\"mot_facts2\", \"state\"]).count().withColumnRenamed(\"mot_facts2\", \"motivation\").withColumnRenamed(\"count\", \"count_2\")\n",
    "df3 = arson_df.groupBy([\"mot_facts3\", \"state\"]).count().withColumnRenamed(\"mot_facts3\", \"motivation\").withColumnRenamed(\"count\", \"count_3\")\n",
    "\n",
    "motives = df1.join(df2, [\"motivation\", \"state\"], \"outer\").join(df3, [\"motivation\", \"state\"], \"outer\").na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-------+-------+-------+-----+\n",
      "|motivation|state|count_1|count_2|count_3|count|\n",
      "+----------+-----+-------+-------+-------+-----+\n",
      "|        13|   NJ|      1|      0|      0|    1|\n",
      "|        43|   MT|      1|      0|      0|    1|\n",
      "|        00|   MO|      1|      0|      0|    1|\n",
      "|        14|   NJ|      3|      1|      0|    4|\n",
      "|        21|   IN|      8|      3|      0|   11|\n",
      "|        23|   NY|      1|      0|      0|    1|\n",
      "|        13|   CA|      7|      2|      0|    9|\n",
      "|        13|   DC|      2|      0|      0|    2|\n",
      "|        63|   HI|      2|      0|      0|    2|\n",
      "|        00|   NE|      7|      2|      0|    9|\n",
      "|        12|   VA|      0|      1|      0|    1|\n",
      "|        22|   MN|      1|      0|      0|    1|\n",
      "|        44|   TX|      2|      1|      0|    3|\n",
      "|        54|   PA|      2|      0|      0|    2|\n",
      "|      null|   AZ|    508|      0|      0|  508|\n",
      "|      null|   AZ|      0|    556|      0|  556|\n",
      "|      null|   SC|    344|      0|      0|  344|\n",
      "|      null|   SC|      0|    400|      0|  400|\n",
      "|      null|   AZ|      0|      0|    561|  561|\n",
      "|      null|   SC|      0|      0|    408|  408|\n",
      "+----------+-----+-------+-------+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "motives_per_state = motives.withColumn(\"count\", sum(motives[col] for col in [\"count_1\", \"count_2\", \"count_3\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = \"count\"\n",
    "STATE = \"state\"\n",
    "UNKNOWNS = [\"UU\", \"NN\", None]\n",
    "\n",
    "def lookup_code(candidate_list, column, codebook):\n",
    "    candidates = [row for row in candidate_list if row[column] not in UNKNOWNS]\n",
    "    if candidates:\n",
    "        return codebook[max(candidates, key=operator.itemgetter(1))[0]]\n",
    "    return None\n",
    "\n",
    "def build_max_count_dicts(df, column, codebook, state_codes=STATES):\n",
    "    results = collections.defaultdict()\n",
    "    for state in state_codes:\n",
    "        count_list = df[df.state==state].select(column, COUNT).collect()\n",
    "        results[state] = lookup_code(count_list, column, codebook)\n",
    "\n",
    "    overall_res_df = df.groupBy(column).agg(functions.sum(COUNT))\n",
    "    results[\"overall\"] = lookup_code(overall_res_df, column, codebook)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATES = [\"AK\", \"AL\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \"LA\", \"ME\", \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_motives(df, column=\"motivation\"):\n",
    "    df1 = df.groupBy([\"mot_facts1\", STATE]).count().withColumnRenamed(\"mot_facts1\", column).withColumnRenamed(COUNT, \"count_1\")\n",
    "    df2 = df.groupBy([\"mot_facts2\", STATE]).count().withColumnRenamed(\"mot_facts2\", column).withColumnRenamed(COUNT, \"count_2\")\n",
    "    df3 = df.groupBy([\"mot_facts3\", STATE]).count().withColumnRenamed(\"mot_facts3\", column).withColumnRenamed(COUNT, \"count_3\")\n",
    "\n",
    "    all_motives = df1.join(df2, [column, STATE], \"outer\").join(df3, [column, STATE], \"outer\").na.fill(0)\n",
    "\n",
    "    motives_per_state = motives.withColumn(COUNT, sum(motives[col] for col in [\"count_1\", \"count_2\", \"count_3\"]))\n",
    "    return build_max_count_dicts(motives_per_state, column, codes.SUSPECTED_MOTIVATION_FACTORS, STATES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_value_2(df, column, codebook, states):\n",
    "    results = collections.defaultdict()\n",
    "    for state in states:\n",
    "        count_list = df[df.state==state].select(column, \"count\").collect()\n",
    "        candidates = [row for row in count_list if row[column] not in [\"UU\", \"NN\", None]]\n",
    "        if candidates:\n",
    "            results[state] = codebook[max(candidates, key=operator.itemgetter(1))[0]]\n",
    "        else:\n",
    "            results[state] = None\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-234-444b3af4c341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_motives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marson_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-233-66bed93630f5>\u001b[0m in \u001b[0;36mget_motives\u001b[0;34m(df, column)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmotives_per_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmotives\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOUNT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmotives\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"count_1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"count_2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"count_3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbuild_max_count_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmotives_per_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSUSPECTED_MOTIVATION_FACTORS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTATES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-231-284da2cb9201>\u001b[0m in \u001b[0;36mbuild_max_count_dicts\u001b[0;34m(df, column, codebook, state_codes)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0moverall_res_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOUNT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"overall\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverall_res_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodebook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-231-284da2cb9201>\u001b[0m in \u001b[0;36mlookup_code\u001b[0;34m(candidate_list, column, codebook)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlookup_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodebook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidate_list\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mUNKNOWNS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcodebook\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/abuckfire/side-projects/arson/fast-facts/spark-2.3.2-bin-hadoop2.7/python/pyspark/sql/column.pyc\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         raise ValueError(\"Cannot convert column into bool: please use '&' for 'and', '|' for 'or', \"\n\u001b[0m\u001b[1;32m    636\u001b[0m                          \"'~' for 'not' when building DataFrame boolean expressions.\")\n\u001b[1;32m    637\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert column into bool: please use '&' for 'and', '|' for 'or', '~' for 'not' when building DataFrame boolean expressions."
     ]
    }
   ],
   "source": [
    "r = get_motives(arson_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_max_value_2(motives_per_state, \"motivation\", codes.SUSPECTED_MOTIVATION_FACTORS, STATES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "motives_overall = motives_per_state.groupBy(\"motivation\").agg(functions.sum(\"count\"))\n",
    "biggest_motive = get_max_value(motives_overall, \"motivation\", codes.SUSPECTED_MOTIVATION_FACTORS)\n",
    "results[\"overall\"] = biggest_motive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: What are the most common materials used for starting a fire?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = arson_df.groupBy([\"state\", \"devi_cont\"]).count()\n",
    "spark_type = arson_df.groupBy([\"state\", \"devi_ignit\"]).count()\n",
    "gas_type = arson_df.groupBy([\"state\", \"devi_fuel\"]).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_value(df, column, codebook):\n",
    "    count_list = df.collect()\n",
    "    candidates = [row for row in count_list if row[column] not in [\"UU\", \"NN\", None]]\n",
    "    return codebook[max(candidates, key=operator.itemgetter(1))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_value_3(df, column, codebook, states):\n",
    "    results = collections.defaultdict()\n",
    "    for state in states:\n",
    "        count_list = df[df.state==state].select(column, \"count\").collect()\n",
    "        candidates = [row for row in count_list if row[column] not in [\"UU\", \"NN\", None]]\n",
    "        if candidates:\n",
    "            results[state] = codebook[max(candidates, key=operator.itemgetter(1))[0]]\n",
    "        else:\n",
    "            results[state] = None\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_results = get_max_value_3(container, \"devi_cont\", codes.INCENDIARY_DEVICES, STATES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "motives_overall_c = container.groupBy(\"devi_cont\").agg(functions.sum(\"count\"))\n",
    "biggest_motive_c = get_max_value(motives_overall_c, \"devi_cont\", codes.INCENDIARY_DEVICES)\n",
    "container_results[\"overall\"] = biggest_motive_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None,\n",
       "            {'AK': 'gasoline or fuel can',\n",
       "             'AL': 'plastic bottle',\n",
       "             'AR': 'gasoline or fuel can',\n",
       "             'AZ': 'can (not gas or fuel)',\n",
       "             'CA': 'gasoline or fuel can',\n",
       "             'CO': 'other container',\n",
       "             'CT': 'gasoline or fuel can',\n",
       "             'DE': 'gasoline or fuel can',\n",
       "             'FL': 'gasoline or fuel can',\n",
       "             'GA': 'gasoline or fuel can',\n",
       "             'HI': 'pressurized container',\n",
       "             'IA': 'gasoline or fuel can',\n",
       "             'ID': 'gasoline or fuel can',\n",
       "             'IL': 'gasoline or fuel can',\n",
       "             'IN': 'gasoline or fuel can',\n",
       "             'KS': 'gasoline or fuel can',\n",
       "             'KY': 'plastic bottle',\n",
       "             'LA': 'gasoline or fuel can',\n",
       "             'MA': 'gasoline or fuel can',\n",
       "             'MD': 'glass bottle',\n",
       "             'ME': 'gasoline or fuel can',\n",
       "             'MI': 'glass bottle',\n",
       "             'MN': 'gasoline or fuel can',\n",
       "             'MO': 'glass bottle',\n",
       "             'MS': 'gasoline or fuel can',\n",
       "             'MT': None,\n",
       "             'NC': 'gasoline or fuel can',\n",
       "             'ND': 'gasoline or fuel can',\n",
       "             'NE': 'gasoline or fuel can',\n",
       "             'NH': 'plastic bottle',\n",
       "             'NJ': 'gasoline or fuel can',\n",
       "             'NM': 'other container',\n",
       "             'NV': 'gasoline or fuel can',\n",
       "             'NY': 'gasoline or fuel can',\n",
       "             'OH': 'gasoline or fuel can',\n",
       "             'OK': 'plastic bottle',\n",
       "             'OR': None,\n",
       "             'PA': 'plastic bottle',\n",
       "             'RI': 'gasoline or fuel can',\n",
       "             'SC': 'gasoline or fuel can',\n",
       "             'SD': None,\n",
       "             'TN': 'gasoline or fuel can',\n",
       "             'TX': 'gasoline or fuel can',\n",
       "             'UT': 'gasoline or fuel can',\n",
       "             'VA': 'gasoline or fuel can',\n",
       "             'VT': 'jug',\n",
       "             'WA': 'gasoline or fuel can',\n",
       "             'WI': 'gasoline or fuel can',\n",
       "             'WV': 'plastic bottle',\n",
       "             'WY': 'jug',\n",
       "             'overall': 'gasoline or fuel can'})"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: What is the most common type of property burned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prop_owner|count|\n",
      "+----------+-----+\n",
      "|         7|    2|\n",
      "|         3|  128|\n",
      "|         0|  243|\n",
      "|      null|47203|\n",
      "|         5|   25|\n",
      "|         1| 7757|\n",
      "|         4|   77|\n",
      "|         2|  500|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "property_ownership = arson_df.groupBy(\"prop_owner\").count()\n",
    "property_ownership.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The primary property type of property affected by arson is: private\n"
     ]
    }
   ],
   "source": [
    "print(\"The primary property type of property affected by arson is: {}\".format(\n",
    "    get_max_value(property_ownership, \"prop_owner\", codes.PROPERTY_OWNERSHIP)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Number of Arsons per Month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"inc_date\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date_by_month(date_string):\n",
    "    month_lookup = {\n",
    "        \"1\": \"January\",\n",
    "        \"2\": \"February\",\n",
    "        \"3\": \"March\",\n",
    "        \"4\": \"April\",\n",
    "        \"5\": \"May\",\n",
    "        \"6\": \"June\",\n",
    "        \"7\": \"July\",\n",
    "        \"8\": \"August\",\n",
    "        \"9\": \"September\",\n",
    "        \"10\": \"October\",\n",
    "        \"11\": \"November\",\n",
    "        \"12\": \"December\"\n",
    "    }\n",
    "    return month_lookup[date_string[:2] if date_string[:2] in month_lookup else date_string[0]]\n",
    "\n",
    "parse_date_by_month_udf = functions.udf(parse_date_by_month, \"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_as_month_df = arson_df.withColumn(date, parse_date_by_month_udf(arson_df[date]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "arson_by_month = date_as_month_df.groupBy(date).count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
