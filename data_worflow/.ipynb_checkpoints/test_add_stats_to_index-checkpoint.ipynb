{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import csv\n",
    "import operator\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions\n",
    "\n",
    "sys.path.append('/Users/abuckfire/side-projects/arson')\n",
    "import static_data.fire_codes.lookup_tables as codes\n",
    "import elastic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = \"count\"\n",
    "STATE = \"state\"\n",
    "UNKNOWNS = [\"UU\", \"NN\", None]\n",
    "STATES = codes.STATES\n",
    "\n",
    "YEARS_AVAILABLE = map(str, range(2009, 2015))\n",
    "FILE_PREFIX = \"nfirs_arson_\"\n",
    "ARSON_PATH = os.path.join(\"..\", \"static_data\", \"nfirs_arson\")\n",
    "\n",
    "FIELDS = {#\"motives\": [\"state\", \"motive\", \"year\"]#,\n",
    "          #\"method\": [\"state\", \"method\", \"year\"],\n",
    "          \"ownership\": [\"state\", \"ownership\", \"year\"],\n",
    "          \"monthly_counts\": [\"state\", \"month\", \"count\", \"year\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_row(d):\n",
    "    return Row(**collections.OrderedDict(sorted(d.items())))\n",
    "\n",
    "\n",
    "def dict_to_df(json, field1, field2, year):\n",
    "    items = [{field1: key, field2: value} for key, value in json.items()]\n",
    "    return sc.parallelize(items).map(convert_to_row).toDF().withColumn(\"year\", functions.lit(year))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_code(candidate_list, column, codebook):\n",
    "    candidates = [row for row in candidate_list if row[column] not in UNKNOWNS]\n",
    "    if candidates:\n",
    "        return codebook[max(candidates, key=operator.itemgetter(1))[0]]\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_max_count_dicts(df, column, codebook, state_codes=STATES):\n",
    "    results = collections.defaultdict()\n",
    "    for state in state_codes:\n",
    "        count_list = df[df.state==state].select(column, COUNT).collect()\n",
    "        results[state] = lookup_code(count_list, column, codebook)\n",
    "\n",
    "    overall_res = df.groupBy(column).agg(functions.sum(COUNT)).alias(COUNT).collect()\n",
    "    results[\"overall\"] = lookup_code(overall_res, column, codebook)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_motives(df, column=\"motivation\"):\n",
    "    df1 = df.groupBy([\"mot_facts1\", STATE]).count().withColumnRenamed(\"mot_facts1\", column).withColumnRenamed(COUNT, \"count_1\")\n",
    "    df2 = df.groupBy([\"mot_facts2\", STATE]).count().withColumnRenamed(\"mot_facts2\", column).withColumnRenamed(COUNT, \"count_2\")\n",
    "    df3 = df.groupBy([\"mot_facts3\", STATE]).count().withColumnRenamed(\"mot_facts3\", column).withColumnRenamed(COUNT, \"count_3\")\n",
    "\n",
    "    motives = df1.join(df2, [column, STATE], \"outer\").join(df3, [column, STATE], \"outer\").na.fill(0)\n",
    "\n",
    "    motives_per_state = motives.withColumn(COUNT, sum(motives[col] for col in [\"count_1\", \"count_2\", \"count_3\"]))\n",
    "    return build_max_count_dicts(motives_per_state, column, codes.SUSPECTED_MOTIVATION_FACTORS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_date_by_month(date_string):\n",
    "    month_lookup = {\n",
    "        \"1\": \"January\",\n",
    "        \"2\": \"February\",\n",
    "        \"3\": \"March\",\n",
    "        \"4\": \"April\",\n",
    "        \"5\": \"May\",\n",
    "        \"6\": \"June\",\n",
    "        \"7\": \"July\",\n",
    "        \"8\": \"August\",\n",
    "        \"9\": \"September\",\n",
    "        \"10\": \"October\",\n",
    "        \"11\": \"November\",\n",
    "        \"12\": \"December\"\n",
    "    }\n",
    "    return month_lookup[date_string[:2] if date_string[:2] in month_lookup else date_string[0]]\n",
    "\n",
    "\n",
    "def get_arson_per_month(df, column=\"inc_date\"):\n",
    "    parse_date_by_month_udf = functions.udf(parse_date_by_month, \"string\")\n",
    "    date_as_month_df = df.withColumn(column, parse_date_by_month_udf(df[column]))\n",
    "    by_state = date_as_month_df.groupBy([column, STATE]).count()\n",
    "    overall = date_as_month_df.groupBy(column).count().withColumn(STATE, functions.lit(\"overall\")).select(column, STATE, COUNT)\n",
    "    return overall.union(by_state).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fast_fact_one_column(df, column, codebook):\n",
    "    df1 = df.groupBy([column, STATE]).count()\n",
    "    return build_max_count_dicts(df1, column, codebook)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stats_with_spark(df):\n",
    "        # Question 1: What is the most common motivation for starting a fire?\n",
    "        motives = get_motives(arson_df)\n",
    "\n",
    "        # Question 2: What are the most common materials used for starting a fire?\n",
    "        method = get_fast_fact_one_column(arson_df, \"devi_ignit\")\n",
    "\n",
    "        # Question 3: What is the most common type of property burned?\n",
    "        ownership = get_fast_fact_one_column(arson_df, \"prop_owner\")\n",
    "\n",
    "        # Question 4: Number of Arsons per Month\n",
    "        monthly_arsons = get_arson_per_month(arson_df)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_facts_to_elastic():\n",
    "    # Initializing Spark Context and reading data in\n",
    "    sqlContext = SQLContext(sc)\n",
    "    spark = SparkSession.builder.enableHiveSupport().getOrCreate()\n",
    "    \n",
    "    for year in [\"2009\"]:\n",
    "        df = spark.read.csv(os.path.join(ARSON_PATH, FILE_PREFIX + year + \".csv\"), header=True)\n",
    "        fast_facts = calculate_stats_with_spark(df)\n",
    "        print fast_facts\n",
    "        print type(fast_facts)\n",
    "        for facts, doc_type in zip(fast_facts, FIELDS): #or zip((fast_facts), FIELDS):??\n",
    "            add_to_index(facts, year, FIELDS[doc_type], doc_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'acknowledged': True}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic.es.indices.delete(index='arson_facts', ignore=[400, 404])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic.es.count(index=\"arson_facts\", doc_type=\"motives\")['count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
