{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import csv\n",
    "import operator\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions\n",
    "\n",
    "sys.path.append('/Users/abuckfire/side-projects/arson')\n",
    "import static_data.fire_codes.lookup_tables as codes\n",
    "import elastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = \"count\"\n",
    "STATE = \"state\"\n",
    "UNKNOWNS = [\"UU\", \"NN\", None]\n",
    "STATES = codes.STATES\n",
    "\n",
    "YEARS_AVAILABLE = map(str, range(2009, 2015))\n",
    "FILE_PREFIX = \"nfirs_arson_\"\n",
    "ARSON_PATH = os.path.join(\"..\", \"static_data\", \"nfirs_arson\")\n",
    "\n",
    "\n",
    "FIELDS = {\"motives\": [\"state\", \"motive\", \"year\"],\n",
    "          \"method\": [\"state\", \"method\", \"year\"],\n",
    "          \"ownership\": [\"state\", \"ownership\", \"year\"],\n",
    "          \"monthly_counts\": [\"state\", \"month\", \"count\", \"year\"]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_code(candidate_list, column, codebook):\n",
    "    candidates = [row for row in candidate_list if row[column] not in UNKNOWNS]\n",
    "    if candidates:\n",
    "        return codebook[max(candidates, key=operator.itemgetter(1))[0]]\n",
    "    return None\n",
    "\n",
    "\n",
    "def build_max_count_dicts(df, column, codebook, state_codes=STATES):\n",
    "    results = collections.defaultdict()\n",
    "    for state in state_codes:\n",
    "        count_list = df[df.state==state].select(column, COUNT).collect()\n",
    "        results[state] = lookup_code(count_list, column, codebook)\n",
    "\n",
    "    overall_res = df.groupBy(column).agg(functions.sum(COUNT)).alias(COUNT).collect()\n",
    "    results[\"overall\"] = lookup_code(overall_res, column, codebook)\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_motives(df, column=\"motivation\"):\n",
    "    df1 = df.groupBy([\"mot_facts1\", STATE]).count().withColumnRenamed(\"mot_facts1\", column).withColumnRenamed(COUNT, \"count_1\")\n",
    "    df2 = df.groupBy([\"mot_facts2\", STATE]).count().withColumnRenamed(\"mot_facts2\", column).withColumnRenamed(COUNT, \"count_2\")\n",
    "    df3 = df.groupBy([\"mot_facts3\", STATE]).count().withColumnRenamed(\"mot_facts3\", column).withColumnRenamed(COUNT, \"count_3\")\n",
    "\n",
    "    motives = df1.join(df2, [column, STATE], \"outer\").join(df3, [column, STATE], \"outer\").na.fill(0)\n",
    "\n",
    "    motives_per_state = motives.withColumn(COUNT, sum(motives[col] for col in [\"count_1\", \"count_2\", \"count_3\"]))\n",
    "    return build_max_count_dicts(motives_per_state, column, codes.SUSPECTED_MOTIVATION_FACTORS)\n",
    "\n",
    "\n",
    "def parse_date_by_month(date_string):\n",
    "    month_lookup = {\n",
    "        \"1\": \"January\",\n",
    "        \"2\": \"February\",\n",
    "        \"3\": \"March\",\n",
    "        \"4\": \"April\",\n",
    "        \"5\": \"May\",\n",
    "        \"6\": \"June\",\n",
    "        \"7\": \"July\",\n",
    "        \"8\": \"August\",\n",
    "        \"9\": \"September\",\n",
    "        \"10\": \"October\",\n",
    "        \"11\": \"November\",\n",
    "        \"12\": \"December\"\n",
    "    }\n",
    "    return month_lookup[date_string[:2] if date_string[:2] in month_lookup else date_string[0]]\n",
    "\n",
    "\n",
    "def get_arson_per_month(df, column=\"inc_date\"):\n",
    "    parse_date_by_month_udf = functions.udf(parse_date_by_month, \"string\")\n",
    "    date_as_month_df = df.withColumn(column, parse_date_by_month_udf(df[column]))\n",
    "    by_state = date_as_month_df.groupBy([column, STATE]).count()\n",
    "    overall = date_as_month_df.groupBy(column).count().withColumn(STATE, functions.lit(\"overall\")).select(column, STATE, COUNT)\n",
    "    return overall.union(by_state).collect()\n",
    "\n",
    "\n",
    "def get_fast_fact_one_column(df, column, codebook):\n",
    "    df1 = df.groupBy([column, STATE]).count()\n",
    "    return build_max_count_dicts(df1, column, codebook)\n",
    "\n",
    "\n",
    "def add_to_elastic(aggs, key, year, index=\"arson\"):\n",
    "    if key == \"monthly_counts\":\n",
    "        for agg in aggs:\n",
    "            elastic.es.index(\n",
    "                index=index,\n",
    "                doc_type=key,\n",
    "                body = dict(zip(FIELDS[key], [agg[STATE], agg[\"inc_date\"], agg[COUNT], year])))\n",
    "    else:\n",
    "        for state, value in aggs.items():\n",
    "            elastic.es.index(\n",
    "                index=index,\n",
    "                doc_type=key,\n",
    "                body = dict(zip(FIELDS[key], [state, value, year])))\n",
    "\n",
    "\n",
    "def calculate_stats_with_spark(df, year):\n",
    "    # Question 1: What is the most common motivation for starting a fire?\n",
    "    motives = get_motives(df)\n",
    "    add_to_elastic(motives, \"motives\", year)\n",
    "\n",
    "    # Question 2: What are the most common materials used for starting a fire?\n",
    "    #method = get_fast_fact_one_column(df, \"devi_ignit\", codes.IGNITION_DELAY_DEVICE)\n",
    "    #add_to_elastic(method, \"method\", year)\n",
    "\n",
    "    # Question 3: What is the most common type of property burned?\n",
    "    #ownership = get_fast_fact_one_column(df, \"prop_owner\", codes.PROPERTY_OWNERSHIP)\n",
    "    #add_to_elastic(ownership, \"method\", year)\n",
    "\n",
    "    # Question 4: Number of Arsons per Month\n",
    "    #monthly_arsons = get_arson_per_month(df)\n",
    "    #add_to_elastic(monthly_arsons, \"monthly_counts\", year)\n",
    "    \n",
    "\n",
    "def ingest_facts_into_es():\n",
    "    # Initializing Spark Context and reading data in\n",
    "    sqlContext = SQLContext(sc)\n",
    "    spark = SparkSession.builder.enableHiveSupport().getOrCreate()\n",
    "    \n",
    "    for year in [\"2013\", \"2014\"]:#YEARS_AVAILABLE:\n",
    "        print year\n",
    "        df = spark.read.csv(os.path.join(ARSON_PATH, FILE_PREFIX + year + \".csv\"), header=True)\n",
    "        calculate_stats_with_spark(df, year)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elastic.create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013\n",
      "2014\n"
     ]
    }
   ],
   "source": [
    "ingest_facts_into_es()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic.es.count(index=\"arson\", doc_type=\"method\", q=\"year:2012\")[\"count\"] # need to ingest 2013 and 2014\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
