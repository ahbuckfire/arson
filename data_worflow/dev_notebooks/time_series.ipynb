{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import collections\n",
    "import csv\n",
    "from datetime import datetime as dt\n",
    "import operator\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions\n",
    "\n",
    "import elastic\n",
    "from lookup_tables import STATES, SUSPECTED_MOTIVATION_FACTORS, IGNITION_DELAY_DEVICE, PROPERTY_OWNERSHIP, MONTHS\n",
    "\n",
    "\n",
    "STATE = \"state\"\n",
    "POP_STATE = \"NAME\"\n",
    "POPULATION_FIELD = \"POPESTIMATE\"\n",
    "POPULATION = \"population\"\n",
    "COUNT = \"count\"\n",
    "\n",
    "UNKNOWNS = [\"UU\", \"NN\", None]\n",
    "\n",
    "YEARS_AVAILABLE = map(str, range(2009, 2015))\n",
    "FILE_PREFIX = \"nfirs_arson_\"\n",
    "ARSON_PATH = os.path.join(\"..\", \"static_data\", \"nfirs_arson\")\n",
    "\n",
    "FIELDS = {\"motives\": [STATE, \"motive\", \"year\"],\n",
    "          \"method\": [STATE, \"method\", \"year\"],\n",
    "          \"ownership\": [STATE, \"ownership\", \"year\"],\n",
    "          \"monthly_counts\": [STATE, \"month\", \"count\", \"year\"],\n",
    "          \"arson_density\" : [STATE, \"count\", \"population\", \"year\", \"pop_density\"]\n",
    "        }\n",
    "\n",
    "\n",
    "def parse_date_by_month(date_string):\n",
    "    if \"-\" not in date_string:\n",
    "        return MONTHS[date_string[:2] if date_string[:2] in MONTHS else date_string[0]]\n",
    "    return MONTHS[str(dt.strptime(date_string, \"%Y-%m-%dT%H:%M:%S\").month)]\n",
    "\n",
    "    \n",
    "def get_arson_per_month(df, column=\"inc_date\"):\n",
    "    parse_date_by_month_udf = functions.udf(parse_date_by_month, \"string\")\n",
    "    date_as_month_df = df.withColumn(column, parse_date_by_month_udf(df[column]))\n",
    "    by_state = date_as_month_df.groupBy([column, STATE]).count()\n",
    "    overall = date_as_month_df.groupBy(column).count().withColumn(STATE, functions.lit(\"overall\")).select(column, STATE, COUNT)\n",
    "    return overall.union(by_state)\n",
    "\n",
    "def ingest_facts_into_es():\n",
    "    # Initializing Spark Context and reading data in\n",
    "    spark = SparkSession.builder.enableHiveSupport().getOrCreate()\n",
    "\n",
    "    state_rename_udf = functions.udf(lambda x: STATES[x.strip()] if STATES.get(x) else 0, \"string\")\n",
    "    dfs = []\n",
    "\n",
    "    for year in YEARS_AVAILABLE:\n",
    "        df = spark.read.csv(os.path.join(ARSON_PATH, FILE_PREFIX + year + \".csv\"), header=True)\n",
    "        dfs.append(get_arson_per_month(df))\n",
    "\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = ingest_facts_into_es()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_overall(dfs, years=[\"2009\", \"2010\", \"2011\", \"2012\", \"2013\", \"2014\"]):\n",
    "    by_months = None\n",
    "    for df, year in zip(dfs, years):\n",
    "        a = df[df.state==\"overall\"].groupBy(\"inc_date\").sum().withColumnRenamed('sum(count)', year)\n",
    "        if by_months:\n",
    "            by_months = by_months.join(a, [\"inc_date\"], \"outer\")\n",
    "        else:\n",
    "            by_months = a\n",
    "        \n",
    "    return by_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts = aggregate_overall(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----+----+----+----+----+----+\n",
      "| inc_date|2009|2010|2011|2012|2013|2014|\n",
      "+---------+----+----+----+----+----+----+\n",
      "|     July|6197|6611|6718|5463|3789|3626|\n",
      "| November|5841|6763|6407|3772|3263|3202|\n",
      "| February|4088|4205|5191|4066|2808|2888|\n",
      "|  January| 325| 308| 343|4664|3319|3586|\n",
      "|    March|4836|5263|5841|4676|3423|3660|\n",
      "|  October|5433|6996|6601|3817|3082|2893|\n",
      "|      May|4797|5458|5734|4788|3748|3747|\n",
      "|   August|4760|5665|5823|4367|3271|3040|\n",
      "|    April|4821|5675|5414|5258|3763|3767|\n",
      "|     June|4883|5340|5925|4730|3233|3251|\n",
      "| December|5727|6751|6745|3220|2955|2567|\n",
      "|September|4227|5373|5013|3746|3043|2789|\n",
      "+---------+----+----+----+----+----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
